{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import re\n",
    "import pandas as pd\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_inputs(inp1,r1,g1,b1,r2,g2,b2,img_path,text):\n",
    "    \n",
    "\n",
    "    #if ask_grad==\"no\":\n",
    "        # ask_side=input(\"In which side you want gradient? \")\n",
    "        # ask_side=ask_side.lower()\n",
    "#         options1 = [\"LEFT\",\"RIGHT\"]\n",
    "#         print(\"1: \"+ options1[0] + \" 2: \"+ options1[1])\n",
    "#         inp1 = input(\"Enter a number: \")\n",
    "\n",
    "\n",
    "#         r1=input(\"Input RGB colors of top color; r: \")\n",
    "        r1=int(r1)\n",
    "#         g1=input(\"Input RGB colors of top color; g: \")\n",
    "        g1=int(g1)\n",
    "#         b1=input(\"Input RGB colors of top color; b: \")\n",
    "        b1=int(b1)\n",
    "\n",
    "#         r2=input(\"Input RGB colors of bottom color; r: \")\n",
    "        r2=int(r2)\n",
    "#         g2=input(\"Input RGB colors of bottom color; g: \")\n",
    "        g2=int(g2)\n",
    "#         b2=input(\"Input RGB colors of bottom color; b: \")\n",
    "        b2=int(b2)\n",
    "\n",
    "        mask_data = []\n",
    "        width= 1080\n",
    "        height= 1080\n",
    "        #print((r1,g1,b1), (r2,g2,b2) )\n",
    "        base = Image.new('RGB', (width, height), (r1,g1,b1))\n",
    "        #base.save(\"base.jpg\")\n",
    "        top = Image.new('RGB', (width, height),(r2,g2,b2))\n",
    "        #top.save(\"top.jpg\")\n",
    "        mask = Image.new('L', (width, height))\n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                mask_data.append(int(300 * (y / height)))\n",
    "        mask.putdata(mask_data)\n",
    "        base.paste(top, (0, 0), mask)\n",
    "        #base.save(\"gguu.jpg\")\n",
    "\n",
    "#         img_path=  #input(\"enter image path: \")\n",
    "#         image = open(img_path, 'rb')\n",
    "#         image_read = image.read()\n",
    "#         image_64_encode = base64.encodestring(image_read)\n",
    "#         image_64_decode = base64.decodestring(image_64_encode)\n",
    "#         image_result = open('decoded_img.png', 'wb') # create a writable image and write the decoding result\n",
    "#         image_result.write(image_64_decode)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        hi, wi, c = img.shape\n",
    "        modelFile = \"/home/abida/Documents/Marketing work/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "        configFile = \"/home/abida/Documents/Marketing work/deploy.prototxt.txt\"\n",
    "        net = cv2.dnn.readNetFromCaffe(configFile, modelFile)\n",
    "\n",
    "        #frame = cv2.imread(img_path)\n",
    "        frame = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        (h, w) = frame.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0,\n",
    "            (300, 300), (104.0, 177.0, 123.0))\n",
    "\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "\n",
    "        for i in range(0, detections.shape[2]):\n",
    "\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "\n",
    "            if confidence > 0.5:\n",
    "\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (x1, y1, x2, y2) = box.astype(\"int\")\n",
    "\n",
    "                texte = \"{:.2f}%\".format(confidence * 100)\n",
    "                y = y1 - 10 if y1 - 10 > 10 else y1 + 10\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2),\n",
    "                              (0, 0, 255), 2)\n",
    "\n",
    "                cv2.putText(frame, texte, (x1, y),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 3)\n",
    "\n",
    "        try:\n",
    "            print(\"Face Detecting Points\")\n",
    "            left_side = x1\n",
    "            print(left_side)\n",
    "            right_side = wi - x2\n",
    "            print(right_side)\n",
    "            face_crop_limit=x1+x2\n",
    "            limit=face_crop_limit\n",
    "        except NameError:\n",
    "            print(\"Body Detecting Points\")\n",
    "            net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "            classes = []\n",
    "            with open(\"coco.names\", \"r\") as f:\n",
    "                classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "            layers_names = net.getLayerNames()\n",
    "            output_layers = [layers_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "            colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, None, fx=0.4, fy=0.4)\n",
    "            height, width, channels = img.shape\n",
    "\n",
    "            blob = cv2.dnn.blobFromImage(img, scalefactor=0.00392, size=(320, 320), mean=(0, 0, 0), swapRB=True, crop=False)\n",
    "            net.setInput(blob)\n",
    "            outputs = net.forward(output_layers)\n",
    "\n",
    "            boxes = []\n",
    "            confs = []\n",
    "            class_ids = []\n",
    "            for output in outputs:\n",
    "                for detect in output:\n",
    "                    scores = detect[5:]\n",
    "                    class_id = np.argmax(scores)\n",
    "                    conf = scores[class_id]\n",
    "                    if conf > 0.3:\n",
    "                        center_x = int(detect[0] * width)\n",
    "                        center_y = int(detect[1] * height)\n",
    "                        wb = int(detect[2] * width)\n",
    "                        hb = int(detect[3] * height)\n",
    "                        xb = int(center_x - wb / 2)\n",
    "                        yb = int(center_y - hb / 2)\n",
    "                        boxes.append([xb, yb, wb, hb])\n",
    "                        confs.append(float(conf))\n",
    "                        class_ids.append(class_id)\n",
    "\n",
    "            indexes = cv2.dnn.NMSBoxes(boxes, confs, 0.5, 0.4)\n",
    "            font = cv2.FONT_HERSHEY_PLAIN\n",
    "            for i in range(len(boxes)):\n",
    "                if i in indexes:\n",
    "                    x1, y1, x2, y2 = boxes[i]\n",
    "                    label = str(classes[class_ids[i]])\n",
    "                    color = colors[i]\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "                    if label == \"person\":\n",
    "                        upper_left = (x1, y1)\n",
    "                        lower_right = (x2, y2)\n",
    "                        cv2.putText(img, label, (x1, y1 - 5), font, 1, color, 1)\n",
    "\n",
    "            left_side=x1\n",
    "            print(left_side)\n",
    "            right_side=wi-x2\n",
    "            print(right_side)\n",
    "            body_crop_limit=wi - x2 + x1\n",
    "            limit=body_crop_limit\n",
    "\n",
    "        if right_side > left_side:\n",
    "            input_img = Image.open(img_path)\n",
    "            box = (0, 0, limit, 1080)\n",
    "            cropped_img = input_img.crop(box)\n",
    "            #cropped_img.save(\"bbb.jpg\")\n",
    "            numpy_image = np.array(cropped_img)\n",
    "            cropped_img = cv2.cvtColor(numpy_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        else:\n",
    "            img = Image.open(img_path)\n",
    "            left = left_side - right_side\n",
    "            top = 0\n",
    "            width = wi\n",
    "            height = 1080\n",
    "            box = (left, top, left + width, top + height)\n",
    "            cropped_img = img.crop(box)\n",
    "            #cropped_img.save(\"bbb.jpg\")\n",
    "            numpy_image = np.array(cropped_img)\n",
    "            \n",
    "            cropped_img = cv2.cvtColor(numpy_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # *****REMOVE BLACK BACKGROUND*****\n",
    "        print(cropped_img)\n",
    "        #cropped_img.save(\"bbb.jpg\")\n",
    "#         cv2.save(cropped_img, \"cc.jpg\")\n",
    "        gray = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2GRAY)\n",
    "        thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "        hh, ww = thresh.shape\n",
    "\n",
    "        thresh[hh - 3:hh, 0:ww] = 0\n",
    "            \n",
    "        white = np.where(thresh == 255)\n",
    "        xmin, ymin, xmax, ymax = np.min(white[1]), np.min(white[0]), np.max(white[1]), np.max(white[0])\n",
    "\n",
    "        final_crop = cropped_img[ymin:ymax + 3, xmin:xmax]\n",
    "        #rint(\"asd\",final_crop)\n",
    "        #cv2.waitKey(0)\n",
    "        #cv2.destroyAllWindows()\n",
    "\n",
    "        color_coverted = cv2.cvtColor(final_crop, cv2.COLOR_BGR2RGB)\n",
    "        final_crop=Image.fromarray(color_coverted)\n",
    "        #final_crop.save(\"bbbb.jpg\")\n",
    "        def crop_center(pil_img, crop_width, crop_height):\n",
    "            img_width, img_height = pil_img.size\n",
    "            return pil_img.crop(((img_width - crop_width) // 2,\n",
    "                                 (img_height - crop_height) // 2,\n",
    "                                 (img_width + crop_width) // 2,\n",
    "                                 (img_height + crop_height) // 2))\n",
    "\n",
    "        exact_size = crop_center(final_crop, 540, 1079)\n",
    "        #exact_size.save(\"sss.jpg\")\n",
    "        print(inp1)\n",
    "\n",
    "        if inp1==\"right\":\n",
    "\n",
    "        #if ask_side==\"right\":\n",
    "            image1 = exact_size\n",
    "            image2 = base\n",
    "            print(image1.size)\n",
    "            print(image2.size)\n",
    "            x1 = 600\n",
    "            y1 = 350\n",
    "\n",
    "        if inp1==\"left\":\n",
    "\n",
    "        # if ask_side==\"left\":\n",
    "            image1 = base\n",
    "            image2 = exact_size\n",
    "            print(image1.size)\n",
    "            print(image2.size)\n",
    "            \n",
    "            x1 = 45\n",
    "            y1 = 350\n",
    "\n",
    "        image1 = image1.resize((540, 1080))\n",
    "        image1_size = image1.size\n",
    "        image2_size = image2.size\n",
    "        new_image = Image.new('RGB',(2*image1_size[0], image1_size[1]), (250,250,250))\n",
    "        new_image.paste(image1,(0,0))\n",
    "        new_image.paste(image2,(image1_size[0],0))\n",
    "        #new_image.show()\n",
    "\n",
    "        def text_wrap(text, font, max_width):\n",
    "            lines = []\n",
    "\n",
    "            if font.getsize(text)[0] <= max_width:\n",
    "                lines.append(text)\n",
    "            else:\n",
    "                words = text.split(' ')\n",
    "                i = 0\n",
    "                while i < len(words):\n",
    "                    line = ''\n",
    "                    while i < len(words) and font.getsize(line + words[i])[0] <= max_width:\n",
    "                        line = line + words[i] + \" \"\n",
    "                        i += 1\n",
    "                    if not line:\n",
    "                        line = words[i]\n",
    "                        i += 1\n",
    "                    lines.append(line)\n",
    "            return lines\n",
    "\n",
    "        stopwords_list = [line.rstrip('\\n') for line in open(\"/home/abida/Documents/Marketing work/stopwords\")]\n",
    "        cap_words=[\"AI\",\"NBI\",\"IEEE\"]\n",
    "        font_path = '/home/abida/Documents/Marketing work/font3.ttf'\n",
    "        font = ImageFont.truetype(font=font_path, size=60)\n",
    "        #text = \"64 PROJECTS FOR EVERY DATA SCIENCE PROFESSIONAL\"\n",
    "#         text=input(\"write text for image: \")\n",
    "        \n",
    "        lowercase_words = re.split(\" \", text.lower())\n",
    "        final_words_low = [lowercase_words[0].capitalize()]\n",
    "        final_words_low += [word if word in stopwords_list else word.capitalize() for word in lowercase_words[1:]]\n",
    "        final_title_low = \" \".join(final_words_low)\n",
    "\n",
    "        lines = text_wrap(final_title_low, font, 540)\n",
    "        line_height = font.getsize('hg')[1]\n",
    "        lines=\"\\n \".join(lines)\n",
    "\n",
    "        draw = ImageDraw.Draw(new_image)\n",
    "        color = 'hsl(0,0%,100%)'\n",
    "        draw.text((x1, y1), lines, fill=color, font=font,align=\"center\")\n",
    "\n",
    "        new_image.save(\"solid.jpg\")\n",
    "\n",
    "\n",
    "# all_inputs(\"2\",\"1\",\"21\",\"21\",\"21\",\"77\",\"21\",\"23\",\"d.png\",\"jhsuiiiabduygb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_input2(inp1,r,g,b,img_path,text):    \n",
    "\n",
    "    #if ask_grad==\"yes\":\n",
    "        # ask_side=input(\"In which side you want gradient? \")\n",
    "        # ask_side=ask_side.lower()\n",
    "#         options1 = [\"LEFT\",\"RIGHT\"]\n",
    "#         print(\"1: \"+ options1[0] + \" 2: \"+ options1[1])\n",
    "#         inp1 = input(\"Enter a number: \")\n",
    "#         r2=input(\"Input RGB colors ; r: \")\n",
    "        r=int(r)\n",
    "#         g2=input(\"Input RGB colors; g: \")\n",
    "        g=int(g)\n",
    "#         b2=input(\"Input RGB colors; b: \")\n",
    "        b=int(b)\n",
    "\n",
    "#         r2=r1\n",
    "#         g2=g1\n",
    "#         b2=b1\n",
    "\n",
    "        mask_data = []\n",
    "        width= 1080\n",
    "        height= 1080\n",
    "        base = Image.new('RGB', (width, height), (r,g,b))\n",
    "        top = Image.new('RGB', (width, height),(r,g,b))\n",
    "        mask = Image.new('L', (width, height))\n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                mask_data.append(int(300 * (y / height)))\n",
    "        mask.putdata(mask_data)\n",
    "        base.paste(top, (0, 0), mask)\n",
    "\n",
    "#         img_path = input(\"enter image path: \")\n",
    "#         image = open(img_path, 'rb')\n",
    "#         image_read = image.read()\n",
    "#         image_64_encode = base64.encodestring(image_read)\n",
    "#         image_64_decode = base64.decodestring(image_64_encode)\n",
    "#         image_result = open('decoded_img.png', 'wb') # create a writable image and write the decoding result\n",
    "#         image_result.write(image_64_decode)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        hi, wi, c = img.shape\n",
    "        modelFile = \"/home/abida/Documents/Marketing work/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "        configFile = \"/home/abida/Documents/Marketing work/deploy.prototxt.txt\"\n",
    "        net = cv2.dnn.readNetFromCaffe(configFile, modelFile)\n",
    "\n",
    "        #frame = cv2.imread(img_path)\n",
    "        frame = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        (h, w) = frame.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0,\n",
    "            (300, 300), (104.0, 177.0, 123.0))\n",
    "\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "\n",
    "        for i in range(0, detections.shape[2]):\n",
    "\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "\n",
    "            if confidence > 0.5:\n",
    "\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (x1, y1, x2, y2) = box.astype(\"int\")\n",
    "\n",
    "                text = \"{:.2f}%\".format(confidence * 100)\n",
    "                y = y1 - 10 if y1 - 10 > 10 else y1 + 10\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2),\n",
    "                              (0, 0, 255), 2)\n",
    "\n",
    "                cv2.putText(frame, text, (x1, y),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 3)\n",
    "\n",
    "        try:\n",
    "            print(\"Face Detecting Points\")\n",
    "            left_side = x1\n",
    "            print(left_side)\n",
    "            right_side = wi - x2\n",
    "            print(right_side)\n",
    "            face_crop_limit=x1+x2\n",
    "            limit=face_crop_limit\n",
    "        except NameError:\n",
    "            print(\"Body Detecting Points\")\n",
    "            net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "            classes = []\n",
    "            with open(\"coco.names\", \"r\") as f:\n",
    "                classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "            layers_names = net.getLayerNames()\n",
    "            output_layers = [layers_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "            colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, None, fx=0.4, fy=0.4)\n",
    "            height, width, channels = img.shape\n",
    "\n",
    "            blob = cv2.dnn.blobFromImage(img, scalefactor=0.00392, size=(320, 320), mean=(0, 0, 0), swapRB=True, crop=False)\n",
    "            net.setInput(blob)\n",
    "            outputs = net.forward(output_layers)\n",
    "\n",
    "            boxes = []\n",
    "            confs = []\n",
    "            class_ids = []\n",
    "            for output in outputs:\n",
    "                for detect in output:\n",
    "                    scores = detect[5:]\n",
    "                    class_id = np.argmax(scores)\n",
    "                    conf = scores[class_id]\n",
    "                    if conf > 0.3:\n",
    "                        center_x = int(detect[0] * width)\n",
    "                        center_y = int(detect[1] * height)\n",
    "                        wb = int(detect[2] * width)\n",
    "                        hb = int(detect[3] * height)\n",
    "                        xb = int(center_x - wb / 2)\n",
    "                        yb = int(center_y - hb / 2)\n",
    "                        boxes.append([xb, yb, wb, hb])\n",
    "                        confs.append(float(conf))\n",
    "                        class_ids.append(class_id)\n",
    "\n",
    "            indexes = cv2.dnn.NMSBoxes(boxes, confs, 0.5, 0.4)\n",
    "            font = cv2.FONT_HERSHEY_PLAIN\n",
    "            for i in range(len(boxes)):\n",
    "                if i in indexes:\n",
    "                    x1, y1, x2, y2 = boxes[i]\n",
    "                    label = str(classes[class_ids[i]])\n",
    "                    color = colors[i]\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "                    if label == \"person\":\n",
    "                        upper_left = (x1, y1)\n",
    "                        lower_right = (x2, y2)\n",
    "                        cv2.putText(img, label, (x1, y1 - 5), font, 1, color, 1)\n",
    "\n",
    "            left_side=x1\n",
    "            print(left_side)\n",
    "            right_side=wi-x2\n",
    "            print(right_side)\n",
    "            body_crop_limit=wi - x2 + x1\n",
    "            limit=body_crop_limit\n",
    "\n",
    "        if right_side > left_side:\n",
    "            input_img = Image.open(img_path)\n",
    "            box = (0, 0, limit, 1080)\n",
    "            cropped_img = input_img.crop(box)\n",
    "            numpy_image = np.array(cropped_img)\n",
    "            cropped_img = cv2.cvtColor(numpy_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        else:\n",
    "            img = Image.open(img_path)\n",
    "            left = left_side - right_side\n",
    "            top = 0\n",
    "            width = wi\n",
    "            height = 1080\n",
    "            box = (left, top, left + width, top + height)\n",
    "            cropped_img = img.crop(box)\n",
    "            numpy_image = np.array(cropped_img)\n",
    "            cropped_img = cv2.cvtColor(numpy_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # *****REMOVE BLACRightK BACKGROUND*****\n",
    "        gray = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2GRAY)\n",
    "        thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "        hh, ww = thresh.shape\n",
    "\n",
    "        thresh[hh - 3:hh, 0:ww] = 0\n",
    "\n",
    "        white = np.where(thresh == 255)\n",
    "        xmin, ymin, xmax, ymax = np.min(white[1]), np.min(white[0]), np.max(white[1]), np.max(white[0])\n",
    "\n",
    "        final_crop = cropped_img[ymin:ymax + 3, xmin:xmax]\n",
    "        print(final_crop)\n",
    "\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "\n",
    "        color_coverted = cv2.cvtColor(final_crop, cv2.COLOR_BGR2RGB)\n",
    "        final_crop=Image.fromarray(color_coverted)\n",
    "        \n",
    "        def crop_center(pil_img, crop_width, crop_height):\n",
    "            img_width, img_height = pil_img.size\n",
    "            return pil_img.crop(((img_width - crop_width) // 2,\n",
    "                                 (img_height - crop_height) // 2,\n",
    "                                 (img_width + crop_width) // 2,\n",
    "                                 (img_height + crop_height) // 2))\n",
    "\n",
    "        exact_size = crop_center(final_crop, 540, 1079)\n",
    "\n",
    "        if inp1 == \"right\":\n",
    "\n",
    "        #if ask_side==\"right\":\n",
    "            image1 = exact_size\n",
    "            image2 = base\n",
    "            x1 = 600\n",
    "            y1 = 350\n",
    "\n",
    "        if inp1==\"left\":\n",
    "        #if ask_side==\"left\":\n",
    "            image1 = base\n",
    "            image2 = exact_size\n",
    "            x1 = 45\n",
    "            y1 = 350\n",
    "\n",
    "        image1 = image1.resize((540, 1080))\n",
    "        image1_size = image1.size\n",
    "        image2_size = image2.size\n",
    "        new_image = Image.new('RGB',(2*image1_size[0], image1_size[1]), (250,250,250))\n",
    "        new_image.paste(image1,(0,0))\n",
    "        new_image.paste(image2,(image1_size[0],0))\n",
    "        #new_image.show()\n",
    "\n",
    "        def text_wrap(text, font, max_width):\n",
    "            lines = []\n",
    "\n",
    "            if font.getsize(text)[0] <= max_width:\n",
    "                lines.append(text)\n",
    "            else:\n",
    "                words = text.split(' ')\n",
    "                i = 0\n",
    "                while i < len(words):\n",
    "                    line = ''\n",
    "                    while i < len(words) and font.getsize(line + words[i])[0] <= max_width:\n",
    "                        line = line + words[i] + \" \"\n",
    "                        i += 1\n",
    "                    if not line:\n",
    "                        line = words[i]\n",
    "                        i += 1\n",
    "                    lines.append(line)\n",
    "            return lines\n",
    "\n",
    "        stopwords_list = [line.rstrip('\\n') for line in open(\"/home/abida/Documents/Marketing work/stopwords\")]\n",
    "        cap_words=[\"AI\",\"NBI\",\"IEEE\"]\n",
    "        font_path = '/home/abida/Documents/Marketing work/font3.ttf'\n",
    "        font = ImageFont.truetype(font=font_path, size=60)\n",
    "        #text = \"64 PROJECTS FOR EVERY DATA SCIENCE PROFESSIONAL\"\n",
    "#         text=input(\"write text for image: \")\n",
    "        lowercase_words = re.split(\" \", text.lower())\n",
    "        final_words_low = [lowercase_words[0].capitalize()]\n",
    "        final_words_low += [word if word in stopwords_list else word.capitalize() for word in lowercase_words[1:]]\n",
    "        final_title_low = \" \".join(final_words_low)\n",
    "\n",
    "        lines = text_wrap(final_title_low, font, 450)\n",
    "        line_height = font.getsize('hg')[1]\n",
    "        lines=\"\\n \".join(lines)\n",
    "\n",
    "        draw = ImageDraw.Draw(new_image)\n",
    "        color = 'hsl(0,0%,100%)'\n",
    "        draw.text((x1, y1), lines, fill=color, font=font,align=\"center\")\n",
    "\n",
    "        new_image.save(\"solid.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import textwrap\n",
    "import re\n",
    "\n",
    "\n",
    "def grad_blend(img_path,r1,g1,b1,r2,g2,b2,text,obesity):\n",
    "    width= 1080\n",
    "    height= 1080\n",
    "    base = Image.new('RGB', (width, height), (r1,g1,b1))\n",
    "    top = Image.new('RGB', (width, height), (r2,g2,b2))\n",
    "    mask = Image.new('L', (width, height))\n",
    "    mask_data = []\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            mask_data.append(int(300 * (y / height)))\n",
    "    mask.putdata(mask_data)\n",
    "    base.paste(top, (0, 0), mask)\n",
    "\n",
    "    Im = Image.open(img_path)\n",
    "#     Im.show()\n",
    "\n",
    "    newIm = Image.new (\"RGBA\", (1080, 1080), (255, 0, 0))\n",
    "    Im2 = base.convert(Im.mode)\n",
    "    Im2 = Im2.resize(Im.size)\n",
    "#     Im2.show()\n",
    "\n",
    "    img = Image.blend(Im,Im2,obesity)\n",
    "#     img.show()\n",
    "    img.save(\"blend.jpg\")\n",
    "\n",
    "    stopwords_list = [line.rstrip('\\n') for line in open(\"/home/abida/Documents/Marketing work/stopwords\")]\n",
    "    lowercase_words = re.split(\" \", text.lower())\n",
    "    text = [lowercase_words[0].capitalize()]\n",
    "    text += [word if word in stopwords_list else word.capitalize() for word in lowercase_words[1:]]\n",
    "    text = \" \".join(text)\n",
    "    iw, ih = img.size\n",
    "\n",
    "    font=ImageFont.truetype(\"/home/abida/Documents/Marketing work/font3.ttf\", 60)\n",
    "    w1, h1 = font.getsize(text)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    textX1 = int((iw - w1) / 2)\n",
    "    lines1 = textwrap.wrap(text, width=35)\n",
    "    startHeight=630\n",
    "    breather=250\n",
    "    y_text1 = h1\n",
    "    for line in lines1:\n",
    "        width, height = font.getsize(line)\n",
    "        draw.text((int((iw - width) / 2), startHeight - breather +y_text1), line, font=font, align=\"left\", color=\"red\")\n",
    "        y_text1 += height\n",
    "\n",
    "    img.save(\"solid.jpg\")\n",
    "\n",
    "# grad_blend(\"/home/sara/Downloads/kirikaono back image.jpg\",255,216,84,205,57,162,\"5 Techniques to Create a Interactive Brand Hashtag\",0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting flask\n",
      "  Using cached Flask-1.1.2-py2.py3-none-any.whl (94 kB)\n",
      "Collecting click>=5.1\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /home/patient/.local/lib/python3.6/site-packages (from flask) (2.11.2)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /home/patient/.local/lib/python3.6/site-packages (from flask) (1.0.1)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Using cached itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/lib/python3/dist-packages (from Jinja2>=2.10.1->flask) (1.0)\n",
      "Installing collected packages: itsdangerous, click, flask\n",
      "Successfully installed click-7.1.2 flask-1.1.2 itsdangerous-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request\n",
    "import os\n",
    "app = Flask(__name__)\n",
    "app.config[\"IMAGE_UPLOADS\"] = \"/home/abida/Documents/Marketing work/images_path\"\n",
    "@app.route(\"/\")\n",
    "def hello():\n",
    "    return render_template(\"index.html\")\n",
    "@app.route(\"/get_image\", methods=['GET', 'POST'])\n",
    "def test():\n",
    "    print(\"hello\")\n",
    "    if request.method == \"POST\":\n",
    "        text = request.form.get('status')\n",
    "        img = request.files[\"media\"]\n",
    "        img.save(os.path.join(app.config[\"IMAGE_UPLOADS\"], img.filename))\n",
    "        fontsize = float(request.form.get(\"fontsize\"))\n",
    "        colors = request.form.get(\"colors\")\n",
    "        opt1 = request.form.get(\"option_box\")\n",
    "        opt2 = request.form.get(\"option_boxx\")\n",
    "        opt3 = request.form.get(\"option_boxxx\")\n",
    "        first = request.form.get(\"first\")\n",
    "        print(opt3)\n",
    "        r1, g1, b1  = tuple(int(first.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))\n",
    "        second = request.form.get(\"second\")\n",
    "        r2, g2, b2  = tuple(int(second.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))\n",
    "        \n",
    "        \n",
    "        solidcolorr = request.form.get(\"solidcolorr\")\n",
    "        r, g, b  = tuple(int(solidcolorr.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))\n",
    "            #(inp1,r1,g1,b1,r2,g2,b2,img_path,text)\n",
    "            #print(img.filename)\n",
    "        if colors=='solid':\n",
    "            all_input2(opt1,r,g,b,app.config[\"IMAGE_UPLOADS\"]+'/'+img.filename,text)\n",
    "#             return send_file('solid.jpg', mimetype='image/JPG')\n",
    "        elif colors=='gradient':\n",
    "            all_inputs(opt1,r1, g1, b1, r2, g2, b2,app.config[\"IMAGE_UPLOADS\"]+'/'+img.filename, text)\n",
    "#             return send_file('solid.jpg', mimetype='image/JPG')\n",
    "        elif colors=='centere':\n",
    "            grad_blend(app.config[\"IMAGE_UPLOADS\"]+'/'+img.filename,r1,g1,b1,r2,g2,b2,text,fontsize)\n",
    "#             return send_file('solid.jpg', mimetype='image/JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:5002/ (Press CTRL+C to quit)\n",
      "[2021-03-09 11:32:57,005] ERROR in app: Exception on / [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/flask/app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/flask/app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/flask/app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-7-b3713d51c862>\", line 7, in hello\n",
      "    return render_template(\"index.html\")\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/flask/templating.py\", line 138, in render_template\n",
      "    ctx.app.jinja_env.get_or_select_template(template_name_or_list),\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/jinja2/environment.py\", line 930, in get_or_select_template\n",
      "    return self.get_template(template_name_or_list, parent, globals)\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/jinja2/environment.py\", line 883, in get_template\n",
      "    return self._load_template(name, self.make_globals(globals))\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/jinja2/environment.py\", line 857, in _load_template\n",
      "    template = self.loader.load(self, name, globals)\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/jinja2/loaders.py\", line 115, in load\n",
      "    source, filename, uptodate = self.get_source(environment, name)\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/flask/templating.py\", line 60, in get_source\n",
      "    return self._get_source_fast(environment, template)\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/flask/templating.py\", line 89, in _get_source_fast\n",
      "    raise TemplateNotFound(template)\n",
      "jinja2.exceptions.TemplateNotFound: index.html\n",
      "127.0.0.1 - - [09/Mar/2021 11:32:57] \"\u001b[35m\u001b[1mGET / HTTP/1.1\u001b[0m\" 500 -\n",
      "127.0.0.1 - - [09/Mar/2021 11:32:57] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "[2021-03-09 11:33:55,900] ERROR in app: Exception on / [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/flask/app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/flask/app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/flask/app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-7-b3713d51c862>\", line 7, in hello\n",
      "    return render_template(\"index.html\")\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/flask/templating.py\", line 138, in render_template\n",
      "    ctx.app.jinja_env.get_or_select_template(template_name_or_list),\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/jinja2/environment.py\", line 930, in get_or_select_template\n",
      "    return self.get_template(template_name_or_list, parent, globals)\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/jinja2/environment.py\", line 883, in get_template\n",
      "    return self._load_template(name, self.make_globals(globals))\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/jinja2/environment.py\", line 857, in _load_template\n",
      "    template = self.loader.load(self, name, globals)\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/jinja2/loaders.py\", line 115, in load\n",
      "    source, filename, uptodate = self.get_source(environment, name)\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/flask/templating.py\", line 60, in get_source\n",
      "    return self._get_source_fast(environment, template)\n",
      "  File \"/home/patient/.local/lib/python3.6/site-packages/flask/templating.py\", line 89, in _get_source_fast\n",
      "    raise TemplateNotFound(template)\n",
      "jinja2.exceptions.TemplateNotFound: index.html\n",
      "127.0.0.1 - - [09/Mar/2021 11:33:55] \"\u001b[35m\u001b[1mGET / HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0',port=5002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
